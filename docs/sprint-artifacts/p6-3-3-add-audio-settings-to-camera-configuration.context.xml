<story-context id="bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>P6-3</epicId>
    <storyId>3.3</storyId>
    <title>Add Audio Settings to Camera Configuration</title>
    <status>ready-for-dev</status>
    <generatedAt>2025-12-17</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/p6-3-3-add-audio-settings-to-camera-configuration.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>home owner</asA>
    <iWant>configure audio capture and audio event detection settings per camera</iWant>
    <soThat>I can enable audio monitoring on specific cameras and choose which sound types to detect</soThat>
    <tasks>
      <task id="1" status="pending">Create AudioSettingsSection component (AC: #1, #2, #3)
        <subtask>Create frontend/components/cameras/AudioSettingsSection.tsx</subtask>
        <subtask>Add toggle switch for audio_enabled field</subtask>
        <subtask>Add checkbox group for audio event type selection</subtask>
        <subtask>Add slider for confidence threshold override (0-100%)</subtask>
        <subtask>Show/hide audio event options based on audio_enabled state</subtask>
        <subtask>Add collapsible section styling consistent with MotionSettingsSection</subtask>
      </task>
      <task id="2" status="pending">Extend CameraForm to include audio settings (AC: #1, #2, #3)
        <subtask>Import and add AudioSettingsSection to CameraForm.tsx</subtask>
        <subtask>Add audio fields to form default values</subtask>
        <subtask>Update form validation schema in lib/validations/camera.ts</subtask>
        <subtask>Ensure audio settings only shown for RTSP cameras (audio not supported for USB)</subtask>
      </task>
      <task id="3" status="pending">Update frontend types and API client (AC: #1, #2, #3)
        <subtask>Add audio_enabled, audio_event_types, audio_threshold to ICamera interface</subtask>
        <subtask>Add fields to ICameraCreate and ICameraUpdate interfaces</subtask>
        <subtask>Ensure API client handles new fields in camera CRUD operations</subtask>
      </task>
      <task id="4" status="pending">Extend Camera model and schema (AC: #1, #2, #3)
        <subtask>Add audio_event_types (JSON array) column to Camera model</subtask>
        <subtask>Add audio_threshold (float, nullable) column for per-camera override</subtask>
        <subtask>Create Alembic migration for new columns</subtask>
        <subtask>Update CameraResponse schema to include audio event settings</subtask>
        <subtask>Update CameraUpdate schema to accept audio event settings</subtask>
      </task>
      <task id="5" status="pending">Add audio indicator to camera status (AC: #4)
        <subtask>Update CameraPreviewCard.tsx with audio indicator</subtask>
        <subtask>Add audio icon when audio_enabled is true</subtask>
        <subtask>Show detected audio codec if available</subtask>
        <subtask>Use Volume2/VolumeX icons from lucide-react</subtask>
      </task>
      <task id="6" status="pending">Write tests (AC: #1-4)
        <subtask>Frontend: Test AudioSettingsSection toggle and checkbox behavior</subtask>
        <subtask>Frontend: Test audio indicator visibility based on audio_enabled</subtask>
        <subtask>Backend: Test migration applies/reverts correctly</subtask>
        <subtask>Backend: Test camera API with audio settings in request/response</subtask>
        <subtask>Backend: Test per-camera threshold override in audio detection</subtask>
      </task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="1">Toggle to enable/disable audio capture per camera in camera form</criterion>
    <criterion id="2">Audio event type selection (checkboxes for which sounds to detect: glass_break, gunshot, scream, doorbell)</criterion>
    <criterion id="3">Sensitivity/confidence threshold slider per camera (override global default)</criterion>
    <criterion id="4">Audio indicator in camera status showing when audio capture is active</criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/epics-phase6.md</path>
        <title>Phase 6 Epics</title>
        <section>Epic P6-3: Audio Analysis Foundation</section>
        <snippet>Story P6-3.3 defines UI for enabling audio capture per camera with event type selection and sensitivity/confidence threshold slider.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-P6-3.md</path>
        <title>Epic P6-3 Technical Specification</title>
        <section>Story P6-3.3: Audio Settings UI</section>
        <snippet>AC16-AC20 define toggle for audio capture, multi-select for event types, slider for threshold (0.5-1.0), audio indicator in camera status, and persistence requirements.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/p6-3-2-implement-audio-event-detection-pipeline.md</path>
        <title>P6-3.2 Story: Audio Event Detection Pipeline</title>
        <section>Dev Agent Record</section>
        <snippet>Provides AudioEventType enum (glass_break, gunshot, scream, doorbell, other), global thresholds API at /api/v1/audio/thresholds, and AlertEngine audio_event_types condition support.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/p6-3-1-add-audio-stream-extraction-from-rtsp.md</path>
        <title>P6-3.1 Story: Audio Stream Extraction</title>
        <section>Dev Agent Record</section>
        <snippet>AudioStreamService available at backend/app/services/audio_stream_service.py. Camera model already has audio_enabled and audio_codec fields.</snippet>
      </doc>
    </docs>

    <code>
      <file>
        <path>frontend/components/cameras/MotionSettingsSection.tsx</path>
        <kind>component</kind>
        <symbol>MotionSettingsSection</symbol>
        <lines>1-291</lines>
        <reason>Reference pattern for collapsible settings section with toggle, select, and input controls. AudioSettingsSection should follow same structure and styling.</reason>
      </file>
      <file>
        <path>frontend/components/cameras/CameraForm.tsx</path>
        <kind>component</kind>
        <symbol>CameraForm</symbol>
        <lines>1-575</lines>
        <reason>Main form component to extend with AudioSettingsSection. Shows how to integrate settings sections and handle conditional display based on camera type.</reason>
      </file>
      <file>
        <path>frontend/components/cameras/CameraPreviewCard.tsx</path>
        <kind>component</kind>
        <symbol>CameraPreviewCard</symbol>
        <lines>1-205</lines>
        <reason>Camera status display component. Add audio indicator (Volume2 icon) in header when audio_enabled is true.</reason>
      </file>
      <file>
        <path>frontend/lib/validations/camera.ts</path>
        <kind>validation</kind>
        <symbol>cameraFormSchema</symbol>
        <lines>1-179</lines>
        <reason>Zod validation schema for camera form. Add audio_enabled, audio_event_types, audio_threshold fields.</reason>
      </file>
      <file>
        <path>frontend/types/camera.ts</path>
        <kind>types</kind>
        <symbol>ICamera, ICameraCreate, ICameraUpdate</symbol>
        <lines>1-173</lines>
        <reason>TypeScript interfaces for camera. Add audio_event_types (string[]), audio_threshold (number) fields. audio_enabled already exists.</reason>
      </file>
      <file>
        <path>backend/app/models/camera.py</path>
        <kind>model</kind>
        <symbol>Camera</symbol>
        <lines>1-151</lines>
        <reason>SQLAlchemy model. Add audio_event_types (JSON array) and audio_threshold (Float, nullable) columns. audio_enabled and audio_codec already exist.</reason>
      </file>
      <file>
        <path>backend/app/schemas/camera.py</path>
        <kind>schema</kind>
        <symbol>CameraResponse, CameraUpdate</symbol>
        <lines>1-299</lines>
        <reason>Pydantic schemas. CameraResponse already has audio_enabled and audio_codec. Add audio_event_types and audio_threshold to both Response and Update schemas.</reason>
      </file>
      <file>
        <path>backend/app/api/v1/audio.py</path>
        <kind>api</kind>
        <symbol>AudioThresholdsResponse</symbol>
        <lines>1-240</lines>
        <reason>Global audio thresholds API. Per-camera threshold override should use same 0.0-1.0 range. Reference AudioEventType enum usage.</reason>
      </file>
      <file>
        <path>backend/app/services/audio_event_detector.py</path>
        <kind>service</kind>
        <symbol>AudioEventDetector</symbol>
        <lines>1-362</lines>
        <reason>Detection service with get_threshold() method. Per-camera override should be checked before global threshold in detect_audio_events().</reason>
      </file>
      <file>
        <path>backend/app/services/audio_classifiers/__init__.py</path>
        <kind>types</kind>
        <symbol>AudioEventType</symbol>
        <reason>Defines enum: GLASS_BREAK, GUNSHOT, SCREAM, DOORBELL, OTHER. Use .value for storage, from_string() for parsing.</reason>
      </file>
      <file>
        <path>backend/alembic/versions/817c9e3ec7f6_add_audio_fields_to_camera.py</path>
        <kind>migration</kind>
        <reason>Existing migration that added audio_enabled and audio_codec. Reference for new migration structure.</reason>
      </file>
    </code>

    <dependencies>
      <python>
        <package name="SQLAlchemy" version="2.0.x">ORM for Camera model</package>
        <package name="Pydantic" version="2.x">Request/response schemas</package>
        <package name="Alembic">Database migrations</package>
      </python>
      <node>
        <package name="react-hook-form" version="^7.x">Form state management</package>
        <package name="zod" version="^3.x">Form validation</package>
        <package name="lucide-react">Icons (Volume2, VolumeX)</package>
        <package name="@radix-ui/react-checkbox">Checkbox component for event types</package>
        <package name="@radix-ui/react-slider">Slider component for threshold</package>
      </node>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="architecture">Audio settings only applicable to RTSP cameras (USB cameras don't support audio extraction)</constraint>
    <constraint type="architecture">Per-camera audio_threshold overrides global threshold from system_settings</constraint>
    <constraint type="data">audio_event_types stored as JSON array in database: ["glass_break", "gunshot", "scream", "doorbell"]</constraint>
    <constraint type="data">audio_threshold nullable float between 0.0 and 1.0 (null = use global default)</constraint>
    <constraint type="ui">AudioSettingsSection should be hidden when camera type is 'usb'</constraint>
    <constraint type="ui">Follow existing MotionSettingsSection styling pattern (border, rounded-lg, bg-muted/20)</constraint>
    <constraint type="testing">Backend tests should cover migration upgrade/downgrade</constraint>
    <constraint type="testing">Frontend tests should use Vitest and React Testing Library</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>AudioEventType Enum</name>
      <kind>enum</kind>
      <signature>
class AudioEventType(str, Enum):
    GLASS_BREAK = "glass_break"
    GUNSHOT = "gunshot"
    SCREAM = "scream"
    DOORBELL = "doorbell"
    OTHER = "other"
      </signature>
      <path>backend/app/services/audio_classifiers/__init__.py</path>
    </interface>
    <interface>
      <name>Camera Update Schema</name>
      <kind>pydantic</kind>
      <signature>
class CameraUpdate(BaseModel):
    audio_enabled: Optional[bool] = None
    audio_event_types: Optional[List[str]] = None  # NEW
    audio_threshold: Optional[float] = Field(None, ge=0.0, le=1.0)  # NEW
      </signature>
      <path>backend/app/schemas/camera.py</path>
    </interface>
    <interface>
      <name>Camera Response Schema</name>
      <kind>pydantic</kind>
      <signature>
class CameraResponse(CameraBase):
    audio_enabled: bool = False
    audio_codec: Optional[str] = None
    audio_event_types: Optional[List[str]] = None  # NEW
    audio_threshold: Optional[float] = None  # NEW
      </signature>
      <path>backend/app/schemas/camera.py</path>
    </interface>
    <interface>
      <name>ICamera Interface</name>
      <kind>typescript</kind>
      <signature>
interface ICamera {
  audio_enabled: boolean;  // existing
  audio_codec?: string;  // existing
  audio_event_types?: string[];  // NEW
  audio_threshold?: number;  // NEW (0.0-1.0)
}
      </signature>
      <path>frontend/types/camera.ts</path>
    </interface>
  </interfaces>

  <tests>
    <standards>
Backend uses pytest with fixtures in conftest.py. Frontend uses Vitest + React Testing Library with setup in vitest.config.ts.
Tests follow AAA pattern (Arrange-Act-Assert). Backend API tests use TestClient. Component tests mock API calls.
Coverage target: 80% for new code.
    </standards>
    <locations>
      <location>backend/tests/test_api/test_cameras.py</location>
      <location>backend/tests/test_services/test_audio_event_detector.py</location>
      <location>frontend/__tests__/components/cameras/</location>
    </locations>
    <ideas>
      <idea ac="1">Test AudioSettingsSection toggle enables/disables audio_enabled field</idea>
      <idea ac="1">Test audio settings hidden when camera type is 'usb'</idea>
      <idea ac="2">Test checkbox group renders all 4 audio event types</idea>
      <idea ac="2">Test selecting/deselecting event types updates form state</idea>
      <idea ac="3">Test slider sets audio_threshold between 0 and 100 (displayed as %)</idea>
      <idea ac="3">Test null threshold uses global default (display "Global Default" option)</idea>
      <idea ac="4">Test CameraPreviewCard shows Volume2 icon when audio_enabled=true</idea>
      <idea ac="4">Test CameraPreviewCard hides audio icon when audio_enabled=false</idea>
      <idea>Backend: Test migration adds audio_event_types and audio_threshold columns</idea>
      <idea>Backend: Test PUT /cameras/{id} accepts and stores audio settings</idea>
      <idea>Backend: Test GET /cameras/{id} returns audio settings in response</idea>
      <idea>Backend: Test per-camera threshold overrides global in AudioEventDetector</idea>
    </ideas>
  </tests>
</story-context>
