<story-context id="p3-4-3-implement-video-upload-to-gemini" v="1.1">
  <metadata>
    <epicId>P3-4</epicId>
    <storyId>P3-4.3</storyId>
    <title>Implement Video Upload to Gemini</title>
    <status>ready-for-dev</status>
    <generatedAt>2025-12-07</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/p3-4-3-implement-video-upload-to-gemini.md</sourceStoryPath>
    <version>1.1 - Updated with Gemini API research findings</version>
  </metadata>

  <story>
    <asA>system</asA>
    <iWant>to send video clips to Google Gemini</iWant>
    <soThat>users get video-native analysis from Gemini for the highest quality event descriptions</soThat>
    <tasks>
      <task id="1" ac="All" status="done">Research Gemini Video API - Two methods: File API (up to 2GB) and inline_data (&lt;20MB)</task>
      <task id="2" ac="1,4">Implement describe_video() method in GeminiProvider - Use inline_data for &lt;20MB, File API for larger</task>
      <task id="3" ac="5">Add video size validation - Check against 2GB File API limit</task>
      <task id="4" ac="2">Implement video format conversion - Add _convert_video_format() using PyAV, support MP4/H.264</task>
      <task id="5" ac="3">Add token/cost tracking for video requests - ~258 tokens/frame at 1fps, calculate cost</task>
      <task id="6" ac="All">Update _try_video_native_analysis() in protect_event_handler - Remove placeholder, call describe_video()</task>
      <task id="7" ac="All">Add AIService orchestration for describe_video - Route to video-capable providers, handle fallback</task>
      <task id="8" ac="All">Write tests - Unit tests for describe_video, validation; integration test for video_native</task>
    </tasks>
  </story>

  <researchFindings>
    <finding priority="critical">
      <summary>Gemini API supports native video upload via two methods</summary>
      <detail>
        1. File API (recommended for videos &gt;20MB): Upload to Google servers (genai.upload_file), wait for processing, then generate_content with file reference. Max 2GB, stored 48 hours.
        2. Inline Data (for videos &lt;20MB): Pass video bytes directly as base64-encoded string. Best for real-time apps with small clips.
      </detail>
    </finding>
    <finding priority="high">
      <summary>Models and capabilities confirmed</summary>
      <detail>Use Gemini 1.5 Flash or Gemini 1.5 Pro. Both are multimodal models optimized for video (process as image frames + audio). Models can "hear" video audio natively.</detail>
    </finding>
    <finding priority="medium">
      <summary>Token usage for video</summary>
      <detail>~258 tokens per frame at 1fps. Longer videos consume more context window. For cost estimation, calculate based on video duration.</detail>
    </finding>
  </researchFindings>

  <acceptanceCriteria>
    <ac id="1">Given video clip under 20MB, when describe_video() called, then video sent as inline_data. For larger videos (20MB-2GB), use File API upload.</ac>
    <ac id="2">Given video needs format conversion, when original format unsupported, then converts to MP4/H.264 using PyAV, retries</ac>
    <ac id="3">Given Gemini video analysis completes, when response received, then token usage tracked (~258 tokens/frame), cost estimate calculated</ac>
    <ac id="4">Given Gemini provider configured with valid API key, when describe_video() called with valid clip, then returns AIResult with description</ac>
    <ac id="5">Given video exceeds 2GB limit, when video analysis attempted, then returns AIResult with success=False, triggers fallback to multi_frame</ac>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/epics-phase3.md</path>
        <title>Phase 3 Epic Breakdown</title>
        <section>Epic P3-4: Native Video Analysis / Story P3-4.3</section>
        <snippet>Story defines acceptance criteria for Gemini video upload including size limits, format conversion, and token tracking. FRs covered: FR19, FR21, FR22.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/p3-4-2-implement-video-upload-to-openai.md</path>
        <title>Previous Story - OpenAI Video Research</title>
        <section>Dev Agent Record / Completion Notes</section>
        <snippet>Critical finding: Only Gemini supports native video upload. OpenAI does NOT support video via API. PROVIDER_CAPABILITIES updated accordingly.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/p3-4-1-add-provider-video-capability-detection.md</path>
        <title>Provider Capability Detection Story</title>
        <section>Implementation</section>
        <snippet>Implemented get_video_capable_providers(), supports_video(), get_all_capabilities() methods in AIService for querying video support.</snippet>
      </doc>
    </docs>

    <code>
      <file>
        <path>backend/app/services/ai_service.py</path>
        <kind>service</kind>
        <symbol>GeminiProvider</symbol>
        <lines>776-945</lines>
        <reason>Target class for adding describe_video() method. Has existing generate_description() and generate_multi_image_description() patterns to follow.</reason>
      </file>
      <file>
        <path>backend/app/services/ai_service.py</path>
        <kind>constant</kind>
        <symbol>PROVIDER_CAPABILITIES</symbol>
        <lines>94-123</lines>
        <reason>Contains Gemini video capabilities: video=True, max_video_duration=60, max_video_size_mb=20, supported_formats=[mp4,mov,webm]</reason>
      </file>
      <file>
        <path>backend/app/services/ai_service.py</path>
        <kind>service-methods</kind>
        <symbol>AIService capability methods</symbol>
        <lines>2271-2400</lines>
        <reason>get_provider_capabilities(), supports_video(), get_video_capable_providers(), get_max_video_duration(), get_max_video_size() - use these for validation</reason>
      </file>
      <file>
        <path>backend/app/services/protect_event_handler.py</path>
        <kind>handler</kind>
        <symbol>_try_video_native_analysis</symbol>
        <lines>1014-1114</lines>
        <reason>Placeholder returning "video_upload_not_implemented" at line 1099. Must update to call actual Gemini video analysis.</reason>
      </file>
      <file>
        <path>backend/tests/test_services/test_ai_service.py</path>
        <kind>test</kind>
        <symbol>AI Service tests</symbol>
        <lines>1-150</lines>
        <reason>Existing test patterns for OpenAI/Claude/Gemini providers. Extend with describe_video() tests.</reason>
      </file>
    </code>

    <dependencies>
      <python>
        <package name="google-generativeai" version=">=0.8.0">Gemini API client - use genai.GenerativeModel for video content</package>
        <package name="av" version=">=12.0.0">PyAV for video processing and format conversion</package>
        <package name="pillow" version=">=10.0.0">Image processing, potentially for video thumbnail</package>
        <package name="tenacity" version=">=8.2.0">Retry logic with exponential backoff</package>
        <package name="pytest" version="7.4.3">Testing framework</package>
        <package name="pytest-asyncio" version="0.21.1">Async test support</package>
      </python>
      <node>
        <package name="next" version="16.0.7">Frontend framework - no changes needed for this story</package>
      </node>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="architecture">Follow existing GeminiProvider pattern: async methods, AIResult return type, structured logging with extra dict</constraint>
    <constraint type="architecture">Use PROVIDER_CAPABILITIES for limits - don't hardcode values in describe_video()</constraint>
    <constraint type="architecture">Fallback chain: video_native failures append to self._fallback_chain list</constraint>
    <constraint type="coding">Token/cost estimation pattern from generate_multi_image_description(): tokens_used = 150 + estimate</constraint>
    <constraint type="coding">Video prompt should use MULTI_FRAME_SYSTEM_PROMPT pattern for temporal narrative</constraint>
    <constraint type="testing">Mock genai library responses in tests - don't make real API calls</constraint>
    <constraint type="testing">Test both success and failure paths including validation errors</constraint>
    <constraint type="performance">Video analysis may be slower - use appropriate timeouts (30s suggested)</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>GeminiProvider.describe_video</name>
      <kind>async method</kind>
      <signature>async def describe_video(self, video_path: Path, camera_name: str, timestamp: str, detected_objects: List[str], custom_prompt: Optional[str] = None) -> AIResult</signature>
      <path>backend/app/services/ai_service.py</path>
    </interface>
    <interface>
      <name>AIService.describe_video</name>
      <kind>async method</kind>
      <signature>async def describe_video(self, video_path: Path, camera_name: str, timestamp: str, detected_objects: List[str], custom_prompt: Optional[str] = None) -> AIResult</signature>
      <path>backend/app/services/ai_service.py</path>
    </interface>
    <interface>
      <name>ai_service.get_video_capable_providers</name>
      <kind>method</kind>
      <signature>def get_video_capable_providers(self) -> List[str]</signature>
      <path>backend/app/services/ai_service.py:2311</path>
    </interface>
    <interface>
      <name>ai_service.get_max_video_duration</name>
      <kind>method</kind>
      <signature>def get_max_video_duration(self, provider: str) -> int</signature>
      <path>backend/app/services/ai_service.py:2343</path>
    </interface>
    <interface>
      <name>ai_service.get_max_video_size</name>
      <kind>method</kind>
      <signature>def get_max_video_size(self, provider: str) -> int</signature>
      <path>backend/app/services/ai_service.py:2356</path>
    </interface>
    <interface>
      <name>genai.GenerativeModel.generate_content_async</name>
      <kind>async method</kind>
      <signature>await model.generate_content_async(parts, generation_config=...)</signature>
      <path>google-generativeai library</path>
    </interface>
  </interfaces>

  <tests>
    <standards>Backend uses pytest with pytest-asyncio for async tests. Mock external APIs using unittest.mock (patch, AsyncMock). Use fixture test_db for database tests. Follow existing patterns in test_ai_service.py.</standards>
    <locations>
      <location>backend/tests/test_services/test_ai_service.py</location>
      <location>backend/tests/test_services/test_fallback_chain.py</location>
    </locations>
    <ideas>
      <idea ac="1">Test GeminiProvider.describe_video() with mocked genai returning valid response</idea>
      <idea ac="2">Test format conversion from unsupported format to MP4</idea>
      <idea ac="3">Test token/cost calculation matches COST_RATES for gemini</idea>
      <idea ac="4">Test describe_video() returns AIResult with success=True on valid video</idea>
      <idea ac="5">Test validation rejects video over 20MB with appropriate error</idea>
      <idea ac="5">Test validation rejects video over 60s with appropriate error</idea>
      <idea ac="All">Test _try_video_native_analysis() calls describe_video() and removes placeholder</idea>
      <idea ac="All">Integration test: video_native mode processes event with Gemini</idea>
    </ideas>
  </tests>
</story-context>
